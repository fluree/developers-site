---
id: classification-project-walkthrough
title: "Semantic Object Classification Project Walkthrough"
---

# Semantic Object Classification Project Walkthrough

The Semantic Object Classification (or ‘SOC’) Project in Classify is a powerful feature that comes with Fluree Sense to allow users to tag or label or classify their Data as a specific attribute.  

This is the implementation of classical machine learning problems such as:  
- Predicting a specific disease based on input features  
- Classifying materials or products based on their names, models, descriptions  
- Classifying whether a loan / credit card will become delinquent or not  
- Detecting fraud and other classification tasks  

---

In this video walkthrough we will:  

- Understand the importance of the SOC project  
- Set up the pre-requisites for it using best practices  
- Run the model and further train it  

By the end, we will generate a fairly accurate ML model showing improvement after each round of training. So let’s get started!

---

## Understanding the SOC Project & Reviewing Available Data

We’ll take a real-world use case & analyze the defined objective of the project as well as the pre-requisite Data for executing this project.

---

## Watch the Video

<div style={{ position: "relative", paddingBottom: "56.25%", height: 0 }}>
  <iframe
    src="https://player.vimeo.com/video/1014510617?h=cf4350ed83&badge=0&autopause=0&player_id=0&app_id=58479"
    frameBorder="0"
    allow="autoplay; fullscreen; picture-in-picture"
    allowFullScreen
    style={{ position: "absolute", top: 0, left: 0, width: "100%", height: "100%" }}
    title="Semantic Object Classification Project Walkthrough"
  />
</div>
# Creating and Running an SOC Project

Creating and running an SOC Project:  
We will create this SOC project live using the available training and test (or ‘Project’) Data.  

For the best results, an **80:20 split** between Training and Test Data should be aimed for. Once created, we’ll run this project.

---

## Watch the Video

<div style={{ position: "relative", paddingBottom: "56.25%", height: 0 }}>
  <iframe
    src="https://player.vimeo.com/video/1014510803?h=1a2073e280&badge=0&autopause=0&player_id=0&app_id=58479"
    frameBorder="0"
    allow="autoplay; fullscreen; picture-in-picture"
    allowFullScreen
    style={{ position: "absolute", top: 0, left: 0, width: "100%", height: "100%" }}
    title="Creating and Running an SOC Project"
  />
</div>

# Reviewing the First Round (Unsupervised Run) Results and Completing Training Tasks

The first run is known as an **Unsupervised run** because there is no manual feedback-based training.  

- The first run generates **training tasks** which project users need to complete by providing feedback on generated predictions.  
- This training is then used to boost the **model accuracy** in subsequent runs.  

---

## Watch the Video

<div style={{ position: "relative", paddingBottom: "56.25%", height: 0 }}>
  <iframe
    src="https://player.vimeo.com/video/1014512178?h=0be9f149a0&badge=0&autopause=0&player_id=0&app_id=58479"
    frameBorder="0"
    allow="autoplay; fullscreen; picture-in-picture"
    allowFullScreen
    style={{ position: "absolute", top: 0, left: 0, width: "100%", height: "100%" }}
    title="Reviewing the First Round (Unsupervised Run) Results and Completing Training Tasks"
  />
</div>

# Re-running the Project after Training (Supervised Run) & Reviewing the Results

Once all training is complete, we run the project again in **Supervised mode** to hopefully see improvement in the model confidence.  

This second run allows us to validate how well the model has improved after incorporating manual feedback from the first round of training.

---

## Watch the Video

<div style={{ position: "relative", paddingBottom: "56.25%", height: 0 }}>
  <iframe
    src="https://player.vimeo.com/video/1014512310?h=420c0fbec1&badge=0&autopause=0&player_id=0&app_id=58479"
    frameBorder="0"
    allow="autoplay; fullscreen; picture-in-picture"
    allowFullScreen
    style={{ position: "absolute", top: 0, left: 0, width: "100%", height: "100%" }}
    title="Re-running the Project after Training (Supervised Run) & Reviewing the Results"
  />
</div>
# SOC Project Confidence Improvement

And now that we completed these steps, as promised in the 4th step, let’s look at the improvement in the model confidence after the first supervised run.  

As we can see, the confidence has improved from **around 75% to 87%**.  

So, following the steps in a **Data Classification (or SOC) project** is likely to allow users to reach a decent level of model confidence. This can be improved further in subsequent runs.  

If you’d like to learn more about classification projects, do refer to our posts on it starting here.

---

## Model Confidence Chart

![SOC Project Confidence Improvement](https://sensedocsdev.wpengine.com/wp-content/uploads/2024/10/2ndrun_confidence.png)


